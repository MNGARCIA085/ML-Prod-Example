{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca8e78f",
   "metadata": {},
   "source": [
    "<!-- ========================= -->\n",
    "<!-- TÍTULO PRINCIPAL CENTRADO -->\n",
    "<!-- ========================= -->\n",
    "\n",
    "<h1 style=\"text-align: center; color: darkblue;\">Tuning Visualization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063d9b0",
   "metadata": {},
   "source": [
    "### 📑 <font color='blue'> Table of Contents </font>\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup](#setup)\n",
    "3. [Helper Functions](#helpers)\n",
    "4. [Results](#results)\n",
    "5. [Analysis](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d1068-f87c-4099-8e16-ed6df80597a2",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## <font color=\"darkred\"> 1. Introduction </font>\n",
    "\n",
    "This notebook presents the results of hyperparameter tuning for several candidate models. The focus is on examining validation metrics such as loss, recall, and F1 score, which are more relevant to our task than accuracy.\n",
    "\n",
    "Each report includes:\n",
    "\n",
    "- Timestamp: when the tuning run was executed.\n",
    "\n",
    "- Model identifier: baseline, variant, or tuned version.\n",
    "\n",
    "- Validation metrics: key performance measures for comparison.\n",
    "\n",
    "- Best hyperparameters: selected configuration from the search process.\n",
    "\n",
    "This approach allows us to quickly review and compare tuning outcomes across different runs, making it easier to identify the most promising setup for further training and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea1c8a",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## <font color=\"darkred\"> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4016e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86b38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options to prevent truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Your existing code\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667defb",
   "metadata": {},
   "source": [
    "<a name=\"helpers\"></a>\n",
    "## <font color=\"darkred\"> 3. Helper Functions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d7ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns data ordered by date\n",
    "def get_data(path):\n",
    "    # Path to runs_index.json\n",
    "    index_path = Path(path)\n",
    "\n",
    "    # Load runs_index.json\n",
    "    with open(index_path) as f:\n",
    "        runs_index = json.load(f)\n",
    "\n",
    "    # Sort by timestamp\n",
    "    runs_index.sort(key=lambda x: x[\"timestamp\"])\n",
    "    \n",
    "    return runs_index\n",
    "\n",
    "\n",
    "# to print results nicely\n",
    "def print_results(log):\n",
    "    \n",
    "    # path to json file\n",
    "    base_dir = \"../\"\n",
    "    path = os.path.join(base_dir, log['json_file'])\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    \n",
    "    # Convert timestamp to readable format\n",
    "    ts = datetime.strptime(data['timestamp'], \"%Y%m%d_%H%M%S\")\n",
    "    print(\"Timestamp:\", ts.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    print(data['model_name'])\n",
    "    print(data['data_variant'])\n",
    "\n",
    "    # Flatten into a vertical DataFrame\n",
    "    val_metrics = pd.DataFrame(list(data['val_metrics'].items()), columns=[\"Metric\", \"Value\"])\n",
    "    best_hparams = pd.DataFrame(list(data['best_hyperparameters'].items()), \n",
    "                                columns=[\"Hyperparameter\", \"Value\"])\n",
    "    \n",
    "    print(\"\\nValidation metrics:\")\n",
    "    print(val_metrics)\n",
    "\n",
    "    print(\"\\nBest hyperparameters:\")\n",
    "    print(best_hparams)\n",
    "    \n",
    "    print(\"\\n-------------------------------------------\\n\")\n",
    "\n",
    "    # return\n",
    "    return val_metrics, best_hparams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f57b48",
   "metadata": {},
   "source": [
    "<a name=\"results\"></a>\n",
    "## <font color=\"darkred\"> 4. Results </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc095591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">Model: Baseline</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2025-09-05 19:21:25\n",
      "baseline_with_tuner\n",
      "simple\n",
      "\n",
      "Validation metrics:\n",
      "      Metric     Value\n",
      "0       loss  0.429325\n",
      "1   accuracy  0.877193\n",
      "2  precision  0.937500\n",
      "3     recall  0.714286\n",
      "4   f1_score  0.810811\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0        learning_rate  0.005449\n",
      "1       trained_epochs        10\n",
      "2           batch_size        64\n",
      "3            optimizer      Adam\n",
      "4  final_learning_rate  0.005449\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Timestamp: 2025-09-05 19:21:36\n",
      "baseline_with_tuner\n",
      "standardize\n",
      "\n",
      "Validation metrics:\n",
      "      Metric    Value\n",
      "0       loss  0.02986\n",
      "1   accuracy  1.00000\n",
      "2  precision  1.00000\n",
      "3     recall  1.00000\n",
      "4   f1_score  1.00000\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0        learning_rate  0.005449\n",
      "1       trained_epochs        10\n",
      "2           batch_size        64\n",
      "3            optimizer      Adam\n",
      "4  final_learning_rate  0.005449\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">Model: No dropout</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2025-09-05 19:21:32\n",
      "build_model_no_dropout_tuner\n",
      "simple\n",
      "\n",
      "Validation metrics:\n",
      "      Metric     Value\n",
      "0       loss  0.514158\n",
      "1   accuracy  0.824561\n",
      "2  precision  0.739130\n",
      "3     recall  0.809524\n",
      "4   f1_score  0.772727\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0        learning_rate  0.005449\n",
      "1       trained_epochs        10\n",
      "2           batch_size        64\n",
      "3            optimizer      Adam\n",
      "4  final_learning_rate  0.005449\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Timestamp: 2025-09-05 19:21:44\n",
      "build_model_no_dropout_tuner\n",
      "standardize\n",
      "\n",
      "Validation metrics:\n",
      "      Metric     Value\n",
      "0       loss  0.021326\n",
      "1   accuracy  1.000000\n",
      "2  precision  1.000000\n",
      "3     recall  1.000000\n",
      "4   f1_score  1.000000\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0        learning_rate  0.005449\n",
      "1       trained_epochs        10\n",
      "2           batch_size        64\n",
      "3            optimizer      Adam\n",
      "4  final_learning_rate  0.005449\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">Model: Dropout</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2025-09-05 19:21:28\n",
      "build_model_with_dropout_tuner\n",
      "simple\n",
      "\n",
      "Validation metrics:\n",
      "      Metric     Value\n",
      "0       loss  0.520492\n",
      "1   accuracy  0.842105\n",
      "2  precision  1.000000\n",
      "3     recall  0.571429\n",
      "4   f1_score  0.727273\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0         dropout_rate       0.4\n",
      "1        learning_rate  0.003328\n",
      "2       trained_epochs        10\n",
      "3           batch_size        64\n",
      "4            optimizer      Adam\n",
      "5  final_learning_rate  0.003328\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Timestamp: 2025-09-05 19:21:39\n",
      "build_model_with_dropout_tuner\n",
      "standardize\n",
      "\n",
      "Validation metrics:\n",
      "      Metric    Value\n",
      "0       loss  0.01423\n",
      "1   accuracy  1.00000\n",
      "2  precision  1.00000\n",
      "3     recall  1.00000\n",
      "4   f1_score  1.00000\n",
      "\n",
      "Best hyperparameters:\n",
      "        Hyperparameter     Value\n",
      "0         dropout_rate       0.4\n",
      "1        learning_rate  0.003328\n",
      "2       trained_epochs        10\n",
      "3           batch_size        64\n",
      "4            optimizer      Adam\n",
      "5  final_learning_rate  0.003328\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"name\": \"Baseline\", \"logs_path\":\"../logs/tuning/baseline_with_tuner/runs_index.json\"},\n",
    "    {\"name\": \"No dropout\", \"logs_path\":\"../logs/tuning/build_model_no_dropout_tuner/runs_index.json\"},\n",
    "    {\"name\": \"Dropout\", \"logs_path\":\"../logs/tuning/build_model_with_dropout_tuner/runs_index.json\"},\n",
    "]\n",
    "\n",
    "for d in data:\n",
    "    display(HTML(f'<span style=\"color:blue; font-size:18px; font-weight:bold;\">'\n",
    "                 f'Model: {d[\"name\"]}</span>'))\n",
    "    for log in get_data(d['logs_path']):\n",
    "        print_results(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3d255",
   "metadata": {},
   "source": [
    "<a name=\"analysis\"></a>\n",
    "## <font color=\"darkred\"> 5. Analysis </font>\n",
    "\n",
    "We can see that, when using standardized data, we achieve excellent results with every model (precision, recall, and F1-score all equal 1). However, this occurs because our problem is very simple."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb4de5f",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: darkblue;\">Inference</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8d630",
   "metadata": {},
   "source": [
    "### üìë <font color='blue'> Table of Contents </font>\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup](#setup)\n",
    "3. [Load model and related components](#load)\n",
    "4. [Get new data](#new_data) \n",
    "5. [Preprocessing](#preprocessing)\n",
    "6. [Predictions](#predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6c02c",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## <font color=\"darkred\"> 1. Introduction </font>\n",
    "\n",
    "In this notebook, we demonstrate how to use our trained model to make predictions on new data.\n",
    "\n",
    "The workflow is as follows:\n",
    "    \n",
    "- Load model and related components (scaler, encoder, etc.)\n",
    "\n",
    "- Get new data\n",
    "\n",
    "- Preprocess the data (scaling, encoding, feature selection, etc.)\n",
    "\n",
    "- Make predictions\n",
    "\n",
    "- Interpret the predictions\n",
    "\n",
    "This order ensures that the data is prepared exactly as during training before generating predictions, and then results can be meaningfully interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c2239",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## <font color=\"darkred\"> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd829a30-b237-472a-9cb4-2259d76512f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d847d6",
   "metadata": {},
   "source": [
    "In this notebook we will focus on the last experiment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "886d3d4d-7965-45f0-b5bc-9828c9e6dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments: ['experiment_baseline_standardize_20250905_192125']\n",
      "Latest experiment: experiment_baseline_standardize_20250905_192125\n",
      "Path to latest: ../outputs/saved_models/experiment_baseline_standardize_20250905_192125\n"
     ]
    }
   ],
   "source": [
    "# get last experiment\n",
    "\n",
    "base_path = \"../outputs/saved_models\"\n",
    "\n",
    "# list all experiment directories\n",
    "experiments = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "# sort them by timestamp at the end of the name\n",
    "experiments.sort()\n",
    "\n",
    "# last one (most recent)\n",
    "latest_experiment = experiments[-1]\n",
    "latest_path = os.path.join(base_path, latest_experiment)\n",
    "\n",
    "print(\"All experiments:\", experiments)\n",
    "print(\"Latest experiment:\", latest_experiment)\n",
    "print(\"Path to latest:\", latest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9b4e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = latest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8d9f3",
   "metadata": {},
   "source": [
    "<a name=\"load\"></a>\n",
    "## <font color=\"darkred\"> 3. Load model and related components </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe20ca6",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acdc948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(experiment_path, \"model.h5\")\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab835a-5e5d-4cb9-85e3-a17dc04b5ff7",
   "metadata": {},
   "source": [
    "**Load column names**\n",
    "\n",
    "Why do we need column names in AI projects?\n",
    "\n",
    "When training a model, the input features have a specific meaning and order. At inference time, if we feed the model data without the same structure, the predictions become unreliable. Column names act as a blueprint: they ensure new data is preprocessed consistently, features are aligned correctly, and nothing is misplaced or missing. Without them, the model might confuse inputs (e.g., treating \"age\" as \"income\"), leading to wrong results.\n",
    "\n",
    "In short: saving column names guarantees that training and inference speak the same ‚Äúlanguage.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "631ed99d-17c5-4a92-9921-6ce959e3aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column names\n",
    "with open(f\"{experiment_path}/columns.json\", \"r\") as f:\n",
    "    columns = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6097b",
   "metadata": {},
   "source": [
    "**Load scaler and encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82fa8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = os.path.join(experiment_path, \"scaler.pkl\")\n",
    "encoder_path = os.path.join(experiment_path, \"encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b8e0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "mean: [1.41559238e+01 1.93511328e+01 9.21518750e+01 6.58153516e+02\n",
      " 9.61988672e-02 1.03554531e-01 8.85161713e-02 4.88897402e-02\n",
      " 1.81255273e-01 6.27087305e-02 4.09529102e-01 1.21794902e+00\n",
      " 2.90134512e+00 4.10547617e+01 6.94725781e-03 2.51113359e-02\n",
      " 3.16497336e-02 1.17416348e-02 2.04345078e-02 3.75897129e-03\n",
      " 1.63169453e+01 2.57480273e+01 1.07621934e+02 8.86556445e+02\n",
      " 1.32138906e-01 2.53280762e-01 2.71695561e-01 1.14682229e-01\n",
      " 2.90017188e-01 8.38891016e-02]\n",
      "var: [1.25668844e+01 1.85788022e+01 5.99698209e+02 1.26879396e+05\n",
      " 2.01562007e-04 2.81310339e-03 6.48463278e-03 1.53749022e-03\n",
      " 7.52674738e-04 4.73514193e-05 8.17568545e-02 3.12598201e-01\n",
      " 4.38201521e+00 2.22211910e+03 8.32386721e-06 2.98804298e-04\n",
      " 9.40867147e-04 3.93270921e-05 6.84521929e-05 6.59908845e-06\n",
      " 2.36568213e+01 3.76441772e+01 1.15197767e+03 3.32406115e+05\n",
      " 5.35499243e-04 2.45697564e-02 4.37180255e-02 4.36030274e-03\n",
      " 3.76101920e-03 3.24277262e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/.local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# scaler\n",
    "scaler = load(scaler_path)\n",
    "\n",
    "# See type of scaler\n",
    "print(type(scaler))\n",
    "\n",
    "# Main learned attributes\n",
    "print(\"mean:\", getattr(scaler, \"mean_\", None)) # mean for every feature\n",
    "print(\"var:\", getattr(scaler, \"var_\", None)) # variance for every feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c786c9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 1, 'B': 0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = joblib.load(encoder_path)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1684a46",
   "metadata": {},
   "source": [
    "<a name=\"new_data\"></a>\n",
    "## <font color=\"darkred\"> 4. Get new data </font>\n",
    "\n",
    "In this example, we will simulate some new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94193a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.39700385e+00, 4.00247407e+01, 6.34840096e+01, 2.06000060e+02,\n",
       "       2.72847655e-02, 2.26122734e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.81165733e-01, 7.59801867e-02, 1.26825215e-01, 2.36744378e+00,\n",
       "       3.73388939e+00, 1.14378116e+01, 3.98669556e-03, 2.59453102e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.42103882e-02, 1.96958698e-03,\n",
       "       1.09367534e+01, 1.50420000e+01, 4.19445884e+01, 2.18346708e+02,\n",
       "       8.44272781e-02, 9.01674345e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.24245112e-01, 2.56945024e-02])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original data for reference\n",
    "original = np.array([7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, 0.0, 0.0,\n",
    "       0.1587, 0.05884, 0.3857, 1.428, 2.548, 19.15, 0.007189, 0.00466,\n",
    "       0.0, 0.0, 0.02676, 0.002783, 9.456, 30.37, 59.16, 268.6, 0.08996,\n",
    "       0.06444, 0.0, 0.0, 0.2871, 0.07039])\n",
    "\n",
    "# Generate a new vector: similar scale, but perturbed enough\n",
    "np.random.seed(42)  # for reproducibility\n",
    "noise_factor = 0.7  # larger factor ‚Üí more difference\n",
    "new_data = original * (1 + noise_factor * (2 * np.random.rand(*original.shape) - 1))\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39103f49",
   "metadata": {},
   "source": [
    "<a name=\"preprocessing\"></a>\n",
    "## <font color=\"darkred\"> 5. Preprocess new data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f22a1aed-5696-45d3-b0d7-67a47fd2c656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.397004</td>\n",
       "      <td>40.024741</td>\n",
       "      <td>63.48401</td>\n",
       "      <td>206.00006</td>\n",
       "      <td>0.027285</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181166</td>\n",
       "      <td>0.07598</td>\n",
       "      <td>...</td>\n",
       "      <td>10.936753</td>\n",
       "      <td>15.042</td>\n",
       "      <td>41.944588</td>\n",
       "      <td>218.346708</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324245</td>\n",
       "      <td>0.025695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     6.397004     40.024741        63.48401  206.00006         0.027285   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          0.022612             0.0                  0.0       0.181166   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07598  ...     10.936753         15.042        41.944588   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  218.346708          0.084427           0.090167              0.0   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                   0.0        0.324245                 0.025695  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column names\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "new_data_df = pd.DataFrame([new_data], columns=columns)\n",
    "\n",
    "# visualization\n",
    "new_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "537c3f6c-4506-4ab2-86f5-5ea7046bdb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.18870618e+00,  4.79631192e+00, -1.17065515e+00,\n",
       "        -1.26937606e+00, -4.85404461e+00, -1.52609816e+00,\n",
       "        -1.09920812e+00, -1.24684236e+00, -3.26372864e-03,\n",
       "         1.92864403e+00, -9.88711742e-01,  2.05595572e+00,\n",
       "         3.97713558e-01, -6.28284966e-01, -1.02615183e+00,\n",
       "        -1.30260681e+00, -1.03182467e+00, -1.87233109e+00,\n",
       "         4.56377834e-01, -6.96565004e-01, -1.10616414e+00,\n",
       "        -1.74493577e+00, -1.93505609e+00, -1.15898629e+00,\n",
       "        -2.06179179e+00, -1.04061246e+00, -1.29942816e+00,\n",
       "        -1.73675198e+00,  5.58120260e-01, -3.23165085e+00]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data = scaler.transform(new_data_df)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef49a6c-4f42-475d-a288-c3b70ef7cc6c",
   "metadata": {},
   "source": [
    "<a name=\"predictions\"></a>\n",
    "## <font color=\"darkred\"> 6. Predictions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc1f0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.0527065e-05]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(scaled_data)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031559d-a406-46fd-b55b-563bd1bd173b",
   "metadata": {},
   "source": [
    "That probability is about 0.0000705 (‚âà0.007%), which is extremely close to zero‚Äîindicating the model is almost certain the tumor is not malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3272b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

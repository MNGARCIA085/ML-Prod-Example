from src.models.utils import get_early_stopping

class ModelTrainer:
    def __init__(self, model_fn, train_ds, val_ds, test_ds, model_name,
                 data_variant="default", log_dir="logs/training", epochs=2,
                 hyperparameters=None, callbacks=None):
        self.model_fn = model_fn
        self.train_ds = train_ds
        self.val_ds = val_ds
        self.test_ds = test_ds
        self.model_name = model_name
        self.data_variant = data_variant
        self.epochs = epochs
        self.hyperparameters = hyperparameters or {}
        self.callbacks = callbacks or []

        # Paths, timestamp, etc. (using your existing utils)
        from src.models.utils import make_run_dirs
        self.run_dir, self.log_file, self.json_file, self.runs_index_file, self.timestamp = make_run_dirs(
            log_dir, model_name, data_variant
        )

    def log(self, msg):
        from src.models.utils import log_message
        log_message(msg, self.log_file)

    def train(self):
        self.log(f"=== Training: {self.model_name} ({self.data_variant}) ===")
        self.model = self.model_fn()

        # Fill missing hyperparameters
        from src.models.utils import extract_optimizer_info
        if "optimizer" not in self.hyperparameters or "learning_rate" not in self.hyperparameters:
            opt_info = extract_optimizer_info(self.model)
            self.hyperparameters.setdefault("optimizer", opt_info["optimizer"])
            self.hyperparameters.setdefault("learning_rate", opt_info["learning_rate"])
        self.hyperparameters["epochs"] = self.epochs

        # Train with optional callbacks
        self.history = self.model.fit(
            self.train_ds,
            validation_data=self.val_ds,
            epochs=self.epochs,
            callbacks=self.callbacks
        )

        # Evaluate
        self.val_loss, self.val_acc, self.val_precision, self.val_recall = self.model.evaluate(self.val_ds)
        self.val_f1 = 2 * (self.val_precision * self.val_recall) / (self.val_precision + self.val_recall + 1e-8)
        self.test_loss, self.test_acc, self.test_precision, self.test_recall = self.model.evaluate(self.test_ds)

        self.save_logs()
        return {
            "model": self.model,
            "history": self.history,
            "val_loss": self.val_loss,
            "val_accuracy": self.val_acc,
            "val_precision": self.val_precision,
            "val_recall": self.val_recall,
            "val_f1": self.val_f1,
            "test_loss": self.test_loss,
            "test_accuracy": self.test_acc,
            "hyperparameters": self.hyperparameters,
            "model_name": self.model_name,
            "data_variant": self.data_variant,
        }

"""

from src.models.trainer import ModelTrainer
from src.models.utils import get_early_stopping

trainer = ModelTrainer(
    model_fn=build_model_with_dropout,
    train_ds=train_ds,
    val_ds=val_ds,
    test_ds=test_ds,
    model_name="dropout_model",
    epochs=20,
    callbacks=[get_early_stopping(patience=5)]
)

results = trainer.train()


UTILS
# src/models/utils.py
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

def get_early_stopping(monitor='val_loss', patience=3, restore_best_weights=True):
    """Return a configured EarlyStopping callback."""
    return EarlyStopping(monitor=monitor, patience=patience, restore_best_weights=restore_best_weights)

def get_reduce_lr_on_plateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6):
    """Return a ReduceLROnPlateau callback."""
    return ReduceLROnPlateau(monitor=monitor, factor=factor, patience=patience, min_lr=min_lr)

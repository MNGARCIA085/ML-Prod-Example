{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb4de5f",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: darkblue;\">Inference</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8d630",
   "metadata": {},
   "source": [
    "### üìë <font color='blue'> Table of Contents </font>\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup](#setup)\n",
    "3. [Helper Functions](#helpers)\n",
    "4. [Results](#results) <br>\n",
    "    4.1. [Metrics](#metrics)<br>\n",
    "    4.2. [Confussion Matrix](#conf_matrix)<br>\n",
    "    4.3. [ROC Curve](#roc_curve)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6c02c",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## <font color=\"darkred\"> 1. Introduction </font>\n",
    "\n",
    "In this notebook, we demonstrate how to use our trained model to make predictions on new data.\n",
    "\n",
    "The workflow is as follows:\n",
    "    \n",
    "- Load model and related components (scaler, encoder, etc.)\n",
    "\n",
    "- Get new data\n",
    "\n",
    "- Preprocess the data (scaling, encoding, feature selection, etc.)\n",
    "\n",
    "- Make predictions\n",
    "\n",
    "- Interpret the predictions\n",
    "\n",
    "This order ensures that the data is prepared exactly as during training before generating predictions, and then results can be meaningfully interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c2239",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## <font color=\"darkred\"> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd829a30-b237-472a-9cb4-2259d76512f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d847d6",
   "metadata": {},
   "source": [
    "In this notebook we will focus on the last experiment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886d3d4d-7965-45f0-b5bc-9828c9e6dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments: ['experiment_baseline_standardize_20250905_192125']\n",
      "Latest experiment: experiment_baseline_standardize_20250905_192125\n",
      "Path to latest: ../outputs/saved_models/experiment_baseline_standardize_20250905_192125\n"
     ]
    }
   ],
   "source": [
    "# get last experiment\n",
    "\n",
    "base_path = \"../outputs/saved_models\"\n",
    "\n",
    "# list all experiment directories\n",
    "experiments = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "# sort them by timestamp at the end of the name\n",
    "experiments.sort()\n",
    "\n",
    "# last one (most recent)\n",
    "latest_experiment = experiments[-1]\n",
    "latest_path = os.path.join(base_path, latest_experiment)\n",
    "\n",
    "print(\"All experiments:\", experiments)\n",
    "print(\"Latest experiment:\", latest_experiment)\n",
    "print(\"Path to latest:\", latest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b4e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = latest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8d9f3",
   "metadata": {},
   "source": [
    "<a name=\"load\"></a>\n",
    "## <font color=\"darkred\"> 3. Load model and related components </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe20ca6",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acdc948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 20:38:27.152858: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(experiment_path, \"model.h5\")\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6097b",
   "metadata": {},
   "source": [
    "**Load scaler and encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82fa8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = os.path.join(experiment_path, \"scaler.pkl\")\n",
    "encoder_path = os.path.join(experiment_path, \"encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8e0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "mean: [1.41559238e+01 1.93511328e+01 9.21518750e+01 6.58153516e+02\n",
      " 9.61988672e-02 1.03554531e-01 8.85161713e-02 4.88897402e-02\n",
      " 1.81255273e-01 6.27087305e-02 4.09529102e-01 1.21794902e+00\n",
      " 2.90134512e+00 4.10547617e+01 6.94725781e-03 2.51113359e-02\n",
      " 3.16497336e-02 1.17416348e-02 2.04345078e-02 3.75897129e-03\n",
      " 1.63169453e+01 2.57480273e+01 1.07621934e+02 8.86556445e+02\n",
      " 1.32138906e-01 2.53280762e-01 2.71695561e-01 1.14682229e-01\n",
      " 2.90017188e-01 8.38891016e-02]\n",
      "var: [1.25668844e+01 1.85788022e+01 5.99698209e+02 1.26879396e+05\n",
      " 2.01562007e-04 2.81310339e-03 6.48463278e-03 1.53749022e-03\n",
      " 7.52674738e-04 4.73514193e-05 8.17568545e-02 3.12598201e-01\n",
      " 4.38201521e+00 2.22211910e+03 8.32386721e-06 2.98804298e-04\n",
      " 9.40867147e-04 3.93270921e-05 6.84521929e-05 6.59908845e-06\n",
      " 2.36568213e+01 3.76441772e+01 1.15197767e+03 3.32406115e+05\n",
      " 5.35499243e-04 2.45697564e-02 4.37180255e-02 4.36030274e-03\n",
      " 3.76101920e-03 3.24277262e-04]\n"
     ]
    }
   ],
   "source": [
    "# scaler\n",
    "scaler = load(scaler_path)\n",
    "\n",
    "# See type of scaler\n",
    "print(type(scaler))\n",
    "\n",
    "# Main learned attributes\n",
    "print(\"mean:\", getattr(scaler, \"mean_\", None)) # mean for every feature\n",
    "print(\"var:\", getattr(scaler, \"var_\", None)) # variance for every feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c786c9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 1, 'B': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = joblib.load(encoder_path)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1684a46",
   "metadata": {},
   "source": [
    "<a name=\"new_data\"></a>\n",
    "## <font color=\"darkred\"> 4. Get new data </font>\n",
    "\n",
    "In this example, we will simulate some new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94193a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48301674e+01 1.69297803e+01 1.62684398e+02 1.13926000e+03\n",
      " 6.13816498e-02 1.43905710e-01 1.14433249e-01 2.11770525e-01\n",
      " 2.76143610e-01 1.01638350e-01 3.60056030e-01 1.50087314e+00\n",
      " 1.25864898e+01 9.16219474e+01 3.54859715e-03 2.73038200e-02\n",
      " 3.84747744e-02 1.64200384e-02 2.71688325e-02 4.38291489e-03\n",
      " 2.93543571e+01 8.58340005e+00 1.30881863e+02 1.64125839e+03\n",
      " 1.52224372e-01 4.47758831e-01 4.12576872e-01 2.70688948e-01\n",
      " 5.19627920e-01 6.53039704e-02]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001,\n",
    "       0.14, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399,\n",
    "       0.04904, 0.053, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6,\n",
    "       2019.0, 0.1622, 0.32, 0.7119, 0.2654, 0.4601, 0.1789])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vector = np.random.rand(30)\n",
    "data = vector\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Original data for reference\n",
    "original = np.array([17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001,\n",
    "                     0.14, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4,\n",
    "                     0.006399, 0.04904, 0.053, 0.01587, 0.03003, 0.006193,\n",
    "                     25.38, 17.33, 184.6, 2019.0, 0.1622, 0.32, 0.7119,\n",
    "                     0.2654, 0.4601, 0.1789])\n",
    "\n",
    "# Generate a new vector: similar scale, but perturbed enough\n",
    "np.random.seed(42)  # for reproducibility\n",
    "noise_factor = 0.7  # larger factor ‚Üí more difference\n",
    "new_data = original * (1 + noise_factor * (2 * np.random.rand(*original.shape) - 1))\n",
    "\n",
    "print(new_data)\n",
    "\n",
    "\n",
    "data = new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39103f49",
   "metadata": {},
   "source": [
    "<a name=\"preprocessing\"></a>\n",
    "## <font color=\"darkred\"> 5. Preprocess new data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3563803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19019672 -0.56175787  2.88020265  1.35065882 -2.45239105  0.76078753\n",
      "   0.32184246  4.15397301  3.45867029  5.65735791 -0.17302418  0.50603055\n",
      "   4.6266769   1.07271689 -1.17799984  0.12683614  0.22250568  0.74602223\n",
      "   0.81395495  0.24288649  2.6804838  -2.79759906  0.68530888  1.30900397\n",
      "   0.86796553  1.24070979  0.67378776  2.36257162  3.74403077 -1.03206579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply scaler (the only thing we need in here)\n",
    "scaled_data = scaler.transform(data.reshape(1,-1))\n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a0b8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc1f0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999996]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(scaled_data)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3272b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ab3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b103d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad0bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d86387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M with prob. 0.9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f4f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c52bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869b133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d61085e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0    14.830167      16.92978      162.684398    1139.26         0.061382   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          0.143906        0.114433             0.211771       0.276144   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                0.101638  ...     29.354357         8.5834       130.881863   \n",
      "\n",
      "    area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0  1641.258386          0.152224           0.447759         0.412577   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              0.270689        0.519628                 0.065304  \n",
      "\n",
      "[1 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# using col names!!!!!!!!!!!!\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "scaler_path = os.path.join(experiment_path, \"scaler.pkl\")\n",
    "\n",
    "\n",
    "# Load column names\n",
    "with open(f\"{experiment_path}/columns.json\", \"r\") as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "# Example new_data array\n",
    "#new_data = np.random.rand(len(columns))  # your new vector\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "new_data_df = pd.DataFrame([new_data], columns=columns)\n",
    "\n",
    "print(new_data_df.head())\n",
    "\n",
    "scaled_data = scaler.transform(new_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66d3fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19019672, -0.56175787,  2.88020265,  1.35065882, -2.45239105,\n",
       "         0.76078753,  0.32184246,  4.15397301,  3.45867029,  5.65735791,\n",
       "        -0.17302418,  0.50603055,  4.6266769 ,  1.07271689, -1.17799984,\n",
       "         0.12683614,  0.22250568,  0.74602223,  0.81395495,  0.24288649,\n",
       "         2.6804838 , -2.79759906,  0.68530888,  1.30900397,  0.86796553,\n",
       "         1.24070979,  0.67378776,  2.36257162,  3.74403077, -1.03206579]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d7ec5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999996]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(scaled_data)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd780957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
